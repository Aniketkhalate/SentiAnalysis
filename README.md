# Senti Analysis.
In this sentiment analysis project, I've embarked on a fascinating journey through the vast realms of online text, leveraging Python and cutting-edge NLP techniques. The primary tool for web scraping was BeautifulSoup, which adeptly harvested content from a curated list of websites. This text was systematically stored in a text file, serving as the foundation for subsequent analysis. <br>

### Features:
<ins> **1. Data Collection with BeautifulSoup:** </ins>
- Collected textual data from various websites. <br>
- Stored the gathered text in an easily accessible text file.

<ins> **2. Text Analysis Metrics:** </ins>

- Syllable Count: Evaluated the complexity of words by counting syllables.
- FOG Index: Calculated to determine the readability and understandability of the text.
- Average Word Length: Provided insights into the lexical sophistication of the content.
- Personal Pronouns: Analyzed to gauge the level of personalization and engagement in the text.
- Average Number of Words per Sentence: Measured sentence complexity and structure.
- Percentage of Complex Words: Identified words with three or more syllables to assess text difficulty.
- Stop Words: Incorporated the analysis of common stop words to focus on meaningful content.

### Integration with Excel
A pivotal aspect of this project was the seamless integration with Excel. The list of websites was maintained in an Excel sheet, which the program utilized for systematic analysis. This ensured a structured and organized approach, allowing for efficient data management and retrieval.

### Insights and Applications
The project culminated in a comprehensive analysis of the textual data, offering valuable insights into the linguistic attributes of the content. By calculating these diverse metrics, the project not only provided a deeper understanding of the text's readability and complexity but also shed light on the nuances of personal engagement and word usage patterns.
